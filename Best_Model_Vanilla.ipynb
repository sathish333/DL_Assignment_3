{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-21T02:39:53.319383Z",
     "iopub.status.busy": "2023-05-21T02:39:53.318714Z",
     "iopub.status.idle": "2023-05-21T02:39:58.993879Z",
     "shell.execute_reply": "2023-05-21T02:39:58.992772Z",
     "shell.execute_reply.started": "2023-05-21T02:39:53.319348Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import wandb\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T03:04:31.793637Z",
     "iopub.status.busy": "2023-05-21T03:04:31.793295Z",
     "iopub.status.idle": "2023-05-21T03:14:50.833719Z",
     "shell.execute_reply": "2023-05-21T03:14:50.832727Z",
     "shell.execute_reply.started": "2023-05-21T03:04:31.793610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 2.3823 Valid Loss: 1.6061 Train Acc: 0.0046  Valid Acc: 0.0562\n",
      "Epoch: 2 Train Loss: 1.0629 Valid Loss: 1.1384 Train Acc: 0.1237  Valid Acc: 0.2603\n",
      "Epoch: 3 Train Loss: 0.7914 Valid Loss: 1.0388 Train Acc: 0.2440  Valid Acc: 0.3540\n",
      "Epoch: 4 Train Loss: 0.6971 Valid Loss: 1.0026 Train Acc: 0.3098  Valid Acc: 0.3540\n",
      "Epoch: 5 Train Loss: 0.6347 Valid Loss: 0.9763 Train Acc: 0.3563  Valid Acc: 0.3918\n",
      "Epoch: 6 Train Loss: 0.5969 Valid Loss: 0.9754 Train Acc: 0.3857  Valid Acc: 0.4019\n",
      "Epoch: 7 Train Loss: 0.5695 Valid Loss: 0.9564 Train Acc: 0.4113  Valid Acc: 0.4175\n",
      "Epoch: 8 Train Loss: 0.5497 Valid Loss: 0.9606 Train Acc: 0.4316  Valid Acc: 0.4080\n",
      "Epoch: 9 Train Loss: 0.5290 Valid Loss: 0.9601 Train Acc: 0.4497  Valid Acc: 0.4260\n",
      "Epoch: 10 Train Loss: 0.5163 Valid Loss: 0.9544 Train Acc: 0.4659  Valid Acc: 0.4221\n",
      "Epoch: 11 Train Loss: 0.5003 Valid Loss: 0.9813 Train Acc: 0.4819  Valid Acc: 0.4346\n",
      "Epoch: 12 Train Loss: 0.4911 Valid Loss: 0.9904 Train Acc: 0.4930  Valid Acc: 0.4309\n",
      "Epoch: 13 Train Loss: 0.4817 Valid Loss: 0.9895 Train Acc: 0.5057  Valid Acc: 0.4561\n",
      "Epoch: 14 Train Loss: 0.4721 Valid Loss: 1.0029 Train Acc: 0.5205  Valid Acc: 0.4482\n",
      "Epoch: 15 Train Loss: 0.4632 Valid Loss: 0.9779 Train Acc: 0.5292  Valid Acc: 0.4443\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "train,valid,test=load_data(data_path,lang)\n",
    "\n",
    "add_start_end(train) #adding start and end characters\n",
    "add_start_end(valid)\n",
    "add_start_end(test)\n",
    "\n",
    "train_src_chars,train_target_chars=get_unique_chars(train) # obtain unique charcaters\n",
    "valid_src_chars,valid_target_chars=get_unique_chars(valid)\n",
    "test_src_chars,test_target_chars=get_unique_chars(test)\n",
    "train_target_chars.add('*') # extra char to handle unknowns in valid and test data.\n",
    "    \n",
    "src_char_idx,src_idx_char=get_char_map(train_src_chars) # create map for each unique charcter to -> integer\n",
    "target_char_idx,target_idx_char=get_char_map(train_target_chars)\n",
    "\n",
    "encoder_vocab_size=len(src_char_idx)+1 # one extra for padding\n",
    "decoder_vocab_size=len(target_char_idx)+1 # one extra for padding\n",
    "\n",
    "max_seq_length=train[0].apply(lambda x:len(x)).max() # maximum sequence lenght in Latin\n",
    "max_target_length=train[1].apply(lambda x:len(x)).max() # maximum target length\n",
    "\n",
    "\n",
    "#creating word vectors\n",
    "train_src_int,train_target_int=vectorize(train,src_char_idx,target_char_idx,max_seq_length)\n",
    "valid_src_int,valid_target_int=vectorize(valid,src_char_idx,target_char_idx,max_seq_length)\n",
    "test_src_int,test_target_int=vectorize(test,src_char_idx,target_char_idx,max_seq_length)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    config.encoder_vocab_size=encoder_vocab_size\n",
    "    config.decoder_vocab_size=decoder_vocab_size\n",
    "    config.max_seq_length=max_seq_length\n",
    "\n",
    "    model=Seq2Seq(config).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        train_loss=0\n",
    "        train_acc=0\n",
    "        model.train()\n",
    "        batch_no=0\n",
    "        for data in get_batch(train_src_int,train_target_int,config.batch_size):\n",
    "#             print(batch_no)\n",
    "            batch_no+=1\n",
    "            x=data[0]\n",
    "            y=data[1]\n",
    "            x=x.to(torch.int64).T\n",
    "            y=y.to(torch.int64).T\n",
    "            outputs,attention_scores=model.forward(x,y)\n",
    "            output=outputs.reshape(-1,outputs.shape[2])\n",
    "            target=y.reshape(-1)\n",
    "            optimizer.zero_grad()\n",
    "            target=target-1\n",
    "            target[target<0]=0\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)# gradient clipping \n",
    "            optimizer.step()# update parameters\n",
    "            train_loss+=loss.item()*config.batch_size\n",
    "\n",
    "            batch_acc=cal_acc(outputs,y)\n",
    "            train_acc+=batch_acc\n",
    "        train_loss/=len(train_src_int)\n",
    "        train_acc/=batch_no \n",
    "        model.eval()\n",
    "\n",
    "        valid_loss=0\n",
    "        valid_acc=0\n",
    "        batch_no=0\n",
    "        with torch.no_grad():# disable storing computation graph\n",
    "            for data in get_batch(valid_src_int,valid_target_int,config.batch_size):\n",
    "                batch_no+=1\n",
    "                x=data[0]\n",
    "                y=data[1]\n",
    "                x=x.to(torch.int64).T\n",
    "                y=y.to(torch.int64).T\n",
    "                outputs,attention_scores=model.forward(x,y,prediction=True)# prediction set to True to disable teacher forcing\n",
    "                output=outputs.reshape(-1,outputs.shape[2])\n",
    "                target=y.reshape(-1)\n",
    "                target=target-1\n",
    "                target[target<0]=0\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss+=loss.item()*config.batch_size\n",
    "                valid_acc+=cal_acc(outputs,y)\n",
    "            valid_loss/=len(valid_src_int)\n",
    "            valid_acc/=batch_no\n",
    "        print(f'Epoch: {epoch+1} Train Loss: {train_loss:.4f} Valid Loss: {valid_loss:.4f} Train Acc: {train_acc:.4f}  Valid Acc: {valid_acc:.4f}')\n",
    "    return model\n",
    "\n",
    "\n",
    "config={'batch_size': 64, 'bidirectional': 'Yes', 'cell_type': 'LSTM', 'decoder_num_layers': 3, 'dropout': 0.2, 'embedding_size': 128, 'encoder_num_layers': 3, 'epochs': 15, 'hidden_size': 256}\n",
    "\n",
    "config=SimpleNamespace(**config)\n",
    "\n",
    "model=main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T03:14:50.836423Z",
     "iopub.status.busy": "2023-05-21T03:14:50.835548Z",
     "iopub.status.idle": "2023-05-21T03:14:52.032252Z",
     "shell.execute_reply": "2023-05-21T03:14:52.031260Z",
     "shell.execute_reply.started": "2023-05-21T03:14:50.836388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is:  0.4111\n"
     ]
    }
   ],
   "source": [
    "# test data predictions into a csv file\n",
    "\n",
    "target_end_index=target_char_idx['$']\n",
    "li=[]\n",
    "batch_no=0\n",
    "test_acc=0\n",
    "for data in get_batch(test_src_int,test_target_int,config.batch_size):\n",
    "    batch_no+=1\n",
    "    x=data[0]\n",
    "    y=data[1]\n",
    "    x=x.to(torch.int64).T\n",
    "    y=y.to(torch.int64).T\n",
    "    target=y.detach().cpu().numpy()\n",
    "    src=x.detach().cpu().numpy()\n",
    "    outputs,_=model.forward(x,y,prediction=True)\n",
    "    batch_acc=cal_acc(outputs,y)\n",
    "    test_acc+=batch_acc\n",
    "    out=outputs.argmax(axis=2).detach().cpu().numpy()+1\n",
    "    for idx in range(out.shape[1]):\n",
    "        each_out=out[:,idx]\n",
    "        each_target=target[:,idx]\n",
    "        each_src=src[:,idx]\n",
    "        src_last_index=np.max(np.nonzero(each_src))\n",
    "        src_str=decode_src(each_src[:src_last_index],src_idx_char)\n",
    "#         print(src_str,end=\" \")\n",
    "        target_last_index=np.max(np.nonzero(each_target))\n",
    "        target_str=decode_target(each_target[:target_last_index],target_idx_char,target_end_index)\n",
    "#         print(target_str,end=\" \")\n",
    "        \n",
    "        for i,value in enumerate(each_out):\n",
    "            if value==target_end_index:\n",
    "                pred_end_index=i\n",
    "                break\n",
    "        pred_str=decode_target(each_out[:pred_end_index],target_idx_char,target_end_index)\n",
    "#         print(pred_str)\n",
    "        li.append([src_str,target_str,pred_str])\n",
    "\n",
    "test_acc/=batch_no\n",
    "print(f\"test accuracy is:  {test_acc:.4f}\")\n",
    "df=pd.DataFrame(li,columns=['Source','Target','Predicted'])\n",
    "df.to_csv('Test_predictions_Vanilla.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T03:17:09.736042Z",
     "iopub.status.busy": "2023-05-21T03:17:09.735536Z",
     "iopub.status.idle": "2023-05-21T03:17:27.891503Z",
     "shell.execute_reply": "2023-05-21T03:17:27.890514Z",
     "shell.execute_reply.started": "2023-05-21T03:17:09.736008Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.login(key='24434976526d9265fdbe2b2150787f46522f5da4')\n",
    "wandb.init(project='Best_Model_Vanilla')\n",
    "\n",
    "wandb.log({'test accuracy':test_acc})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
